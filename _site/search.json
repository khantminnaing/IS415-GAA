[
  {
    "objectID": "Hands-on_Ex/hands_on04.html",
    "href": "Hands-on_Ex/hands_on04.html",
    "title": "Hands-On Exercise 03",
    "section": "",
    "text": "Spatial weights are a key component in any cross-sectional analysis of spatial dependence. They are an essential element in the construction of spatial autocorrelation statistics, and provide the means to create spatially explicit variables, such as spatially lagged variables and spatially smoothed rates.\nComputing spatial weight is an essential step toward measuring the strength of the spatial relationships between objects. In this exercise, the basic concept of spatial weight will be introduced. This is followed by a discussion of methods to compute spatial weights.\nParticularly, we will explore using spdep, an R package specially designed for spatial weight analysis.\n\n\n\nIn this hands-on exercise, we will use the following R package:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspdep,\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\ntidyverse\nknitr\n\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)\n\n\n\n\nIn this exercise, we will use the following datasets:\n\nHunan county boundary layer. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv This csv file contains selected Hunan's local development indicators in 2012.\n\n\n\nIn this section, st_read() of sf package will be used to import the three geospatial data sets mentioned in previous section into R environment.\n\nhunan &lt;- st_read(dsn = \"../data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/khantminnaing/IS415-GAA/data/geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nIn this section, read_csv() of sf package will be used to import the csv file into R environment. The output is R dataframe class.\n\nhunan2012 &lt;- read_csv(\"../data/aspatial/Hunan_2012.csv\")\nhunan2012\n\n# A tibble: 88 × 29\n   County    City   avg_wage deposite    FAI Gov_Rev Gov_Exp    GDP GDPPC    GIO\n   &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 Anhua     Yiyang    30544   10967   6832.    457.   2703  13225  14567  9277.\n 2 Anren     Chenz…    28058    4599.  6386.    221.   1455.  4941. 12761  4189.\n 3 Anxiang   Chang…    31935    5517.  3541     244.   1780. 12482  23667  5109.\n 4 Baojing   Hunan…    30843    2250   1005.    193.   1379.  4088. 14563  3624.\n 5 Chaling   Zhuzh…    31251    8241.  6508.    620.   1947  11585  20078  9158.\n 6 Changning Hengy…    28518   10860   7920     770.   2632. 19886  24418 37392 \n 7 Changsha  Chang…    54540   24332  33624    5350    7886. 88009  88656 51361 \n 8 Chengbu   Shaoy…    28597    2581.  1922.    161.   1192.  2570. 10132  1681.\n 9 Chenxi    Huaih…    33580    4990   5818.    460.   1724.  7755. 17026  6644.\n10 Cili      Zhang…    33099    8117.  4498.    500.   2306. 11378  18714  5843.\n# ℹ 78 more rows\n# ℹ 19 more variables: Loan &lt;dbl&gt;, NIPCR &lt;dbl&gt;, Bed &lt;dbl&gt;, Emp &lt;dbl&gt;,\n#   EmpR &lt;dbl&gt;, EmpRT &lt;dbl&gt;, Pri_Stu &lt;dbl&gt;, Sec_Stu &lt;dbl&gt;, Household &lt;dbl&gt;,\n#   Household_R &lt;dbl&gt;, NOIP &lt;dbl&gt;, Pop_R &lt;dbl&gt;, RSCG &lt;dbl&gt;, Pop_T &lt;dbl&gt;,\n#   Agri &lt;dbl&gt;, Service &lt;dbl&gt;, Disp_Inc &lt;dbl&gt;, RORP &lt;dbl&gt;, ROREmp &lt;dbl&gt;\n\n\n\n\n\n\n\n\nIn previous section, we have imported a shapefile hunan representing the geographical boundaries of Hunan and a dataframe hunan2012 which contains the attribute fields corresponding to counties in Hunan.\nThe next step in our analysis involves updating the attribute table of the hunan shapefile with the values from hunan2012.\nHence, we will need to update the attribute table of Hunan by using left_join() of dplyr package. This function effectively merges the two datasets, ensuring that each county's geographical data is accurately linked with its corresponding attribute data from the hunan2012 dataframe.\n\nhunan &lt;- left_join(hunan,hunan2012, join_by(County))%&gt;%\n  select(1:4, 7, 15)\n\n\n\n\n\nIn this section, we will carry out exploratory spatial data anlysis.\n\n\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nbasemap &lt;- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.2)\n\ngdppc &lt;- qtm(hunan, \"GDPPC\", fill.palette = \"plasma\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\nIn this section, we will explore how to use poly2nb() of spdep package to compute contiguity weight matrices for the study area.\nThe poly2nb() function accepts an argument named queen, which can be set to either TRUE or FALSE. This argument plays a pivotal role in determining the criteria used for identifying neighboring regions. If the queen argument is not explicitly specified, the function defaults to TRUE and the function will generate a list of first-order neighbors using the Queen's contiguity criteria.\n\n\nWe will start out by computing Queen contiguity weight matrix\n\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one heighbours.\n\n\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. To see the neighbors for the first polygon in the object, we can just use the following code chunk:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbors. The numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class. We can retrive the county name of Polygon ID=1 by using the code chunk below:\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nThe output reveals that Polygon ID=1 is Anxiang county.\nTo reveal the county names of the five neighboring polygons, the code chunk will be used:\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can retrieve the GDPPC of these five countries by using the code chunk below.\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nThe printed output above shows that the GDPPC of the five nearest neighbours based on Queen's method are 20981, 34592, 24473, 21311 and 22879 respectively.\nYou can display the complete weight matrix by using str() function.\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\n\n\nIn previous section, we have created neighbours based on QUEEN contiguity. In this section, we will try ROOK contiguity to create another set of neighbours which we will call wm_r.\n\nwm_r &lt;- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connect area unit has 10 neighbours. There are two area units with only one neighbours.\n\n\n\n\nA connectivity graph takes a point and displays a line to each neighboring point. We are working with polygons at the moment, so we will need to get points in order to make our connectivity graphs. The most typically method for this will be polygon centroids. We will calculate these in the sf package before moving onto the graphs. Getting Latitude and Longitude of Polygon Centroids\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid() on the sf object. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column. We will be using map_dbl variation of map from the purrr package.\nTo get our longitude values we map the st_centroid function over the geometry column of us.bound and access the longitude value through double bracket notation [[]]and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\nThen, we will check the first few observations to see if the coordinates are formatted properly.\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\nOnce we have extracted the coordinates of the centroid of each map unit, we will go ahead and plot neighbours maps.\n\n\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"grey\")\n\n\n\n\n\n\n\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"grey\")\n\n\n\n\n\n\n\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"grey\")\nplot(hunan$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"grey\")\n\n\n\n\n\n\n\n\n\nIn this section, we will explore how to derive distance-based weight matrices by using dnearneigh() of spdep package.\nThe function identifies neighbours of region points by Euclidean distance with a distance band with lower d1= and upper d2= bounds controlled by the bounds= argument. If unprojected coordinates are used and either specified in the coordinates object x or with x as a two column matrix and longlat=TRUE, great circle distances in km will be calculated assuming the WGS84 reference ellipsoid.\n\n\nFirstly, we need to determine the upper limit for distance band. This can be achieved by following the steps below.\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\n\n\n\n\n\n\nTip\n\n\n\nAverage number of links: 3.681818\" in the output refers to the average number of neighboring regions each region has within the distance range of 0-62km. In the context of spatial analysis, a \"link\" is a connection between two regions that are considered neighbors based on the criteria we have set (in this case, distance of up to 62km).\nSo, an average of 3.681818 means that, on average, each region in our study area has about 3 to 4 neighboring regions within a distance of 62 units.\n\n\nNext, we will use str() to display the content of wm_d62 weight matrix. This time, we will combine table() and card() of spdep to display the matrix more neatly than simply using str().\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\n\nNext, we will plot the distance weight matrix by using the code chunk below.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"purple\", length=0.08)\n\n\n\n\nThe purple lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nAlternatively, we can plot both of them next to each other by using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1, coords, add=TRUE, col=\"purple\", length=0.08)\nplot(hunan$geometry, border=\"lightgrey\", main=\"Distance link\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)\n\n\n\n\n\n\n\n\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nSimilarly, we can display the content of the matrix by using str().\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\nNotably, it is observed that each county has exactly six neighbours.\n\n\nWe can plot the adoptive weight matrix we obtained in previous section using the code chunk below.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"purple\")"
  },
  {
    "objectID": "Hands-on_Ex/hands_on04.html#overview",
    "href": "Hands-on_Ex/hands_on04.html#overview",
    "title": "Hands-On Exercise 03",
    "section": "",
    "text": "Spatial weights are a key component in any cross-sectional analysis of spatial dependence. They are an essential element in the construction of spatial autocorrelation statistics, and provide the means to create spatially explicit variables, such as spatially lagged variables and spatially smoothed rates.\nComputing spatial weight is an essential step toward measuring the strength of the spatial relationships between objects. In this exercise, the basic concept of spatial weight will be introduced. This is followed by a discussion of methods to compute spatial weights.\nParticularly, we will explore using spdep, an R package specially designed for spatial weight analysis."
  },
  {
    "objectID": "Hands-on_Ex/hands_on04.html#importing-packages",
    "href": "Hands-on_Ex/hands_on04.html#importing-packages",
    "title": "Hands-On Exercise 03",
    "section": "",
    "text": "In this hands-on exercise, we will use the following R package:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspdep,\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\ntidyverse\nknitr\n\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/hands_on04.html#importing-datasets-to-r-environment",
    "href": "Hands-on_Ex/hands_on04.html#importing-datasets-to-r-environment",
    "title": "Hands-On Exercise 03",
    "section": "",
    "text": "In this exercise, we will use the following datasets:\n\nHunan county boundary layer. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv This csv file contains selected Hunan's local development indicators in 2012.\n\n\n\nIn this section, st_read() of sf package will be used to import the three geospatial data sets mentioned in previous section into R environment.\n\nhunan &lt;- st_read(dsn = \"../data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/khantminnaing/IS415-GAA/data/geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nIn this section, read_csv() of sf package will be used to import the csv file into R environment. The output is R dataframe class.\n\nhunan2012 &lt;- read_csv(\"../data/aspatial/Hunan_2012.csv\")\nhunan2012\n\n# A tibble: 88 × 29\n   County    City   avg_wage deposite    FAI Gov_Rev Gov_Exp    GDP GDPPC    GIO\n   &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 Anhua     Yiyang    30544   10967   6832.    457.   2703  13225  14567  9277.\n 2 Anren     Chenz…    28058    4599.  6386.    221.   1455.  4941. 12761  4189.\n 3 Anxiang   Chang…    31935    5517.  3541     244.   1780. 12482  23667  5109.\n 4 Baojing   Hunan…    30843    2250   1005.    193.   1379.  4088. 14563  3624.\n 5 Chaling   Zhuzh…    31251    8241.  6508.    620.   1947  11585  20078  9158.\n 6 Changning Hengy…    28518   10860   7920     770.   2632. 19886  24418 37392 \n 7 Changsha  Chang…    54540   24332  33624    5350    7886. 88009  88656 51361 \n 8 Chengbu   Shaoy…    28597    2581.  1922.    161.   1192.  2570. 10132  1681.\n 9 Chenxi    Huaih…    33580    4990   5818.    460.   1724.  7755. 17026  6644.\n10 Cili      Zhang…    33099    8117.  4498.    500.   2306. 11378  18714  5843.\n# ℹ 78 more rows\n# ℹ 19 more variables: Loan &lt;dbl&gt;, NIPCR &lt;dbl&gt;, Bed &lt;dbl&gt;, Emp &lt;dbl&gt;,\n#   EmpR &lt;dbl&gt;, EmpRT &lt;dbl&gt;, Pri_Stu &lt;dbl&gt;, Sec_Stu &lt;dbl&gt;, Household &lt;dbl&gt;,\n#   Household_R &lt;dbl&gt;, NOIP &lt;dbl&gt;, Pop_R &lt;dbl&gt;, RSCG &lt;dbl&gt;, Pop_T &lt;dbl&gt;,\n#   Agri &lt;dbl&gt;, Service &lt;dbl&gt;, Disp_Inc &lt;dbl&gt;, RORP &lt;dbl&gt;, ROREmp &lt;dbl&gt;"
  },
  {
    "objectID": "Hands-on_Ex/hands_on04.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/hands_on04.html#geospatial-data-wrangling",
    "title": "Hands-On Exercise 03",
    "section": "",
    "text": "In previous section, we have imported a shapefile hunan representing the geographical boundaries of Hunan and a dataframe hunan2012 which contains the attribute fields corresponding to counties in Hunan.\nThe next step in our analysis involves updating the attribute table of the hunan shapefile with the values from hunan2012.\nHence, we will need to update the attribute table of Hunan by using left_join() of dplyr package. This function effectively merges the two datasets, ensuring that each county's geographical data is accurately linked with its corresponding attribute data from the hunan2012 dataframe.\n\nhunan &lt;- left_join(hunan,hunan2012, join_by(County))%&gt;%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "Hands-on_Ex/hands_on04.html#exploratory-spatial-data-analysis",
    "href": "Hands-on_Ex/hands_on04.html#exploratory-spatial-data-analysis",
    "title": "Hands-On Exercise 03",
    "section": "",
    "text": "In this section, we will carry out exploratory spatial data anlysis.\n\n\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nbasemap &lt;- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.2)\n\ngdppc &lt;- qtm(hunan, \"GDPPC\", fill.palette = \"plasma\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/hands_on04.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/hands_on04.html#computing-contiguity-spatial-weights",
    "title": "Hands-On Exercise 03",
    "section": "",
    "text": "In this section, we will explore how to use poly2nb() of spdep package to compute contiguity weight matrices for the study area.\nThe poly2nb() function accepts an argument named queen, which can be set to either TRUE or FALSE. This argument plays a pivotal role in determining the criteria used for identifying neighboring regions. If the queen argument is not explicitly specified, the function defaults to TRUE and the function will generate a list of first-order neighbors using the Queen's contiguity criteria.\n\n\nWe will start out by computing Queen contiguity weight matrix\n\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one heighbours.\n\n\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. To see the neighbors for the first polygon in the object, we can just use the following code chunk:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbors. The numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class. We can retrive the county name of Polygon ID=1 by using the code chunk below:\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nThe output reveals that Polygon ID=1 is Anxiang county.\nTo reveal the county names of the five neighboring polygons, the code chunk will be used:\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can retrieve the GDPPC of these five countries by using the code chunk below.\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nThe printed output above shows that the GDPPC of the five nearest neighbours based on Queen's method are 20981, 34592, 24473, 21311 and 22879 respectively.\nYou can display the complete weight matrix by using str() function.\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\n\n\nIn previous section, we have created neighbours based on QUEEN contiguity. In this section, we will try ROOK contiguity to create another set of neighbours which we will call wm_r.\n\nwm_r &lt;- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connect area unit has 10 neighbours. There are two area units with only one neighbours.\n\n\n\n\nA connectivity graph takes a point and displays a line to each neighboring point. We are working with polygons at the moment, so we will need to get points in order to make our connectivity graphs. The most typically method for this will be polygon centroids. We will calculate these in the sf package before moving onto the graphs. Getting Latitude and Longitude of Polygon Centroids\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid() on the sf object. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column. We will be using map_dbl variation of map from the purrr package.\nTo get our longitude values we map the st_centroid function over the geometry column of us.bound and access the longitude value through double bracket notation [[]]and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\nThen, we will check the first few observations to see if the coordinates are formatted properly.\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\nOnce we have extracted the coordinates of the centroid of each map unit, we will go ahead and plot neighbours maps.\n\n\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"grey\")\n\n\n\n\n\n\n\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"grey\")\n\n\n\n\n\n\n\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"grey\")\nplot(hunan$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"grey\")"
  },
  {
    "objectID": "Hands-on_Ex/hands_on04.html#computing-distance-based-neighbours",
    "href": "Hands-on_Ex/hands_on04.html#computing-distance-based-neighbours",
    "title": "Hands-On Exercise 03",
    "section": "",
    "text": "In this section, we will explore how to derive distance-based weight matrices by using dnearneigh() of spdep package.\nThe function identifies neighbours of region points by Euclidean distance with a distance band with lower d1= and upper d2= bounds controlled by the bounds= argument. If unprojected coordinates are used and either specified in the coordinates object x or with x as a two column matrix and longlat=TRUE, great circle distances in km will be calculated assuming the WGS84 reference ellipsoid.\n\n\nFirstly, we need to determine the upper limit for distance band. This can be achieved by following the steps below.\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\n\n\n\n\n\n\nTip\n\n\n\nAverage number of links: 3.681818\" in the output refers to the average number of neighboring regions each region has within the distance range of 0-62km. In the context of spatial analysis, a \"link\" is a connection between two regions that are considered neighbors based on the criteria we have set (in this case, distance of up to 62km).\nSo, an average of 3.681818 means that, on average, each region in our study area has about 3 to 4 neighboring regions within a distance of 62 units.\n\n\nNext, we will use str() to display the content of wm_d62 weight matrix. This time, we will combine table() and card() of spdep to display the matrix more neatly than simply using str().\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\n\nNext, we will plot the distance weight matrix by using the code chunk below.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"purple\", length=0.08)\n\n\n\n\nThe purple lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nAlternatively, we can plot both of them next to each other by using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1, coords, add=TRUE, col=\"purple\", length=0.08)\nplot(hunan$geometry, border=\"lightgrey\", main=\"Distance link\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)\n\n\n\n\n\n\n\n\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nSimilarly, we can display the content of the matrix by using str().\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\nNotably, it is observed that each county has exactly six neighbours.\n\n\nWe can plot the adoptive weight matrix we obtained in previous section using the code chunk below.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"purple\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01.html",
    "title": "Take-Home Exercise 01: Spatial Point Patterns Analysis of Grab Trajectories in Singapore",
    "section": "",
    "text": "Human mobility, the spatial-temporal dynamics of human movements, serves as a critical reflection of societal patterns and human behaviors. With the advancement and pervasiveness of Information and Communication Technologies (ICT) in our daily life, especially smart phone, a large volume of data related to human mobility have been collected. These data provide valuable insights into understanding how individuals and populations move within and between different geographical locations. By using appropriate GIS analysis methods, these data can turn into valuable inisghts for predicting future mobility trrends and developing more efficient and sustainable strategies for managing urban mobility.\nIn this study, I will apply Spatial Point Patterns Analysis methods to discover the geographical and spatio-temporal distribution of Grab hailing services locations in Singapore. In order to determine the geographical and spatio-temporal patterns of the Grab hailing services, I will develop traditional Kernel Density Estimation (KDE) and Temporal Network Kernel Density Estimation (TNKDE). KDE layers will help identify the areas with high concentration of Grab hailing services, providing insights into the demand and popularity of these services in different parts of Singapore. TNKDE, on the other hand, will allow for analysis of how the distribution of Grab hailing services changes over time, revealing temporal patterns and trends in their usage. These spatial and spatio-temporal analyses will contribute to a better understanding of the dynamics and effectiveness of Grab’s mobility services in Singapore."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01.html#introduction",
    "href": "Take-home_Ex/Take-home_Ex01.html#introduction",
    "title": "Take-Home Exercise 01: Spatial Point Patterns Analysis of Grab Trajectories in Singapore",
    "section": "",
    "text": "Human mobility, the spatial-temporal dynamics of human movements, serves as a critical reflection of societal patterns and human behaviors. With the advancement and pervasiveness of Information and Communication Technologies (ICT) in our daily life, especially smart phone, a large volume of data related to human mobility have been collected. These data provide valuable insights into understanding how individuals and populations move within and between different geographical locations. By using appropriate GIS analysis methods, these data can turn into valuable inisghts for predicting future mobility trrends and developing more efficient and sustainable strategies for managing urban mobility.\nIn this study, I will apply Spatial Point Patterns Analysis methods to discover the geographical and spatio-temporal distribution of Grab hailing services locations in Singapore. In order to determine the geographical and spatio-temporal patterns of the Grab hailing services, I will develop traditional Kernel Density Estimation (KDE) and Temporal Network Kernel Density Estimation (TNKDE). KDE layers will help identify the areas with high concentration of Grab hailing services, providing insights into the demand and popularity of these services in different parts of Singapore. TNKDE, on the other hand, will allow for analysis of how the distribution of Grab hailing services changes over time, revealing temporal patterns and trends in their usage. These spatial and spatio-temporal analyses will contribute to a better understanding of the dynamics and effectiveness of Grab’s mobility services in Singapore."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01.html#literature-review-of-spatial-point-pattern-analysis",
    "href": "Take-home_Ex/Take-home_Ex01.html#literature-review-of-spatial-point-pattern-analysis",
    "title": "Take-Home Exercise 01: Spatial Point Patterns Analysis of Grab Trajectories in Singapore",
    "section": "2.0 Literature Review of Spatial Point Pattern Analysis",
    "text": "2.0 Literature Review of Spatial Point Pattern Analysis\nSpatial point pattern analysis is concerned with description, statistical characterization, modeling and visulisation of point patterns over space and making inference about the process that could have generated an observed pattern (Boots & Getis, 1988 ,Rey et al., 2023; Pebesma & Bivand, 2023). According to this theory, empirical spatial distribution of points in our daily life are not controlled by sampling, but a result of an underlying geographically-continuous process (Rey et al., 2023). For example, an COVID-19 cluster did not happen by chance, but due to a spatial process of close-contact infection.\nWhen analysing real-world spatial points, it is important to analyse whether the observed spatial points are randomly distributed or patterned due to a process or interaction (Floch et al., 2018). In “complete random” distribution, points are located everywhere with the same probability and independently of each other. On the other hand, the spatial points can be clustered or dispersed due to an underlying point process. However, it is challenging to use heuristic observation and intuitive interpretation to detect whether a spatial point pattern exists (Baddeley et al., 2015; Floch et al., 2018). Hence, spatial point pattern analysis can be used to detect the spatial concentration or dispersion phenomena.\n\nWhen analysing and interpreting the properties of a point pattern, these properties can be categorized into two: (a) first-order properties and (b) second-order properties (Yuan et al., 2020; Gimond, 2023). First-order properties concern with the characteristics of individual point locations and their variations of their density across space (Gimond, 2023). Under this conception, observations vary from point to point due to changes in the underlying property. Second-order properties focus on not only individual points, but also the interactions between points and their influences on one another (Gimond, 2023). Under this conception, observations vary from place to place due to interaction effects between observations. First-order properties of point patterns are mostly addressed by density-based techniques, such as quadrat analysis and kernel density estimation, whereas, distance-based techniques, such nearest neighbour index and K-functions, are often used to analyse second-order properties since they take into account the distance between point pairs (Yuan et al., 2020; Gimond, 2023)."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01.html#importing-packages",
    "href": "Take-home_Ex/Take-home_Ex01.html#importing-packages",
    "title": "Take-Home Exercise 01: Spatial Point Patterns Analysis of Grab Trajectories in Singapore",
    "section": "3.0 Importing Packages",
    "text": "3.0 Importing Packages\nBefore we start the exercise, we will need to import necessary R packages first. We will use the following packages:\n\narrow : for reading and writing Apache Parquet files\nlubridate : for tackling with temporal data (dates and times)\nspatstat: A package for statistical analysis of spatial data, specifically Spatial Point Pattern Analysis. This package was provided by Baddeley, Turner and Ruback (2015) and gives a comprehensive list of functions to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\nrgdal: Used to import geospatial data and output as spatial class objects from sp package\nraster : reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\nmaptools, ggplot2, ggthemes, plotly: Packages used to plot interactive visualisations summary statistics and KDE layers\n\n\npacman::p_load(arrow,lubridate,tidyverse,tmap,sf,st,spatstat,patchwork,raster)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01.html#importing-datasets-into-r-environment",
    "href": "Take-home_Ex/Take-home_Ex01.html#importing-datasets-into-r-environment",
    "title": "Take-Home Exercise 01: Spatial Point Patterns Analysis of Grab Trajectories in Singapore",
    "section": "4.0 Importing Datasets into R Environment",
    "text": "4.0 Importing Datasets into R Environment\n\n4.1 Datasets\nIn this study, we will use Grab-Posisi dataset, which is a comprehensive GPS trajectory dataset for car-hailing services in Southeast Asia. Apart from the time and location of the object, GPS trajectories are also characterised by other parameters such as speed, the headed direction, the area and distance covered during its travel, and the travelled time. Thus, the trajectory patterns from users GPS data are a valuable source of information for a wide range of urban applications, such as solving transportation problems, traffic prediction, and developing reasonable urban planning.\nMoreover, we will also use OpenStreetMap dataset, which is an open-sourced geospatial dataset including shapefiles of important layers including road networks, forests, building footprints and many other points of interest.\nTo extract the Singapore boundary, we will use Master Plan 2019 Subzone Boundary (No Sea), provided by data.gov.sg.\n\n\n4.2 Importing Grab-Posisi Dataset\nEach trajectory in Grab-Posisi dataset is serialised in a file in Apache Parquet format. The Singapore portion of the dataset is packaged into a total of 10 Parquet files.\nFirstly, we will use read_parquet function from arrow package, which allows us to read Parquet files into R environment as a data frame (more specifically, a tibble).\n\ndf &lt;- read_parquet('~/IS415-GAA/data/GrabPosisi/part-00000.snappy.parquet',as_data_frame = TRUE)\ndf1 &lt;- read_parquet('~/IS415-GAA/data/GrabPosisi/part-00001.snappy.parquet',as_data_frame = TRUE)\ndf2 &lt;- read_parquet('~/IS415-GAA/data/GrabPosisi/part-00002.snappy.parquet',as_data_frame = TRUE)\ndf3 &lt;- read_parquet('~/IS415-GAA/data/GrabPosisi/part-00003.snappy.parquet',as_data_frame = TRUE)\ndf4 &lt;- read_parquet('~/IS415-GAA/data/GrabPosisi/part-00004.snappy.parquet',as_data_frame = TRUE)\ndf5 &lt;- read_parquet('~/IS415-GAA/data/GrabPosisi/part-00005.snappy.parquet',as_data_frame = TRUE)\ndf6 &lt;- read_parquet('~/IS415-GAA/data/GrabPosisi/part-00006.snappy.parquet',as_data_frame = TRUE)\ndf7 &lt;- read_parquet('~/IS415-GAA/data/GrabPosisi/part-00007.snappy.parquet',as_data_frame = TRUE)\ndf8 &lt;- read_parquet('~/IS415-GAA/data/GrabPosisi/part-00008.snappy.parquet',as_data_frame = TRUE)\ndf9 &lt;- read_parquet('~/IS415-GAA/data/GrabPosisi/part-00009.snappy.parquet',as_data_frame = TRUE)\n\nTo consolidate all trajectory instances into a single dataframe, we’ll vertically bind all 10 imported dataframes using bind_rows() function from tidyverse package.\n\ndf_trajectories &lt;- bind_rows(df,df1,df2,df3,df4,df5,df6,df7,df8,df9)\n\nTo get a quick overview of the dataset, we’ll first check the number of trajectory instances using dim() function. Then, we’ll use head() function to quickly scan through the data columns and values\n\ndim(df_trajectories)\n\n[1] 30329685        9\n\nhead(df_trajectories)\n\n# A tibble: 6 × 9\n  trj_id driving_mode osname  pingtimestamp rawlat rawlng speed bearing accuracy\n  &lt;chr&gt;  &lt;chr&gt;        &lt;chr&gt;           &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;int&gt;    &lt;dbl&gt;\n1 70014  car          android    1554943236   1.34   104.  18.9     248      3.9\n2 73573  car          android    1555582623   1.32   104.  17.7      44      4  \n3 75567  car          android    1555141026   1.33   104.  14.0      34      3.9\n4 1410   car          android    1555731693   1.26   104.  13.0     181      4  \n5 4354   car          android    1555584497   1.28   104.  14.8      93      3.9\n6 32630  car          android    1555395258   1.30   104.  23.2      73      3.9\n\n\nFrom the result above, we can see that the dataset includes a total of 30329685 trajectory instances, each with a total of 9 columns as follows:\n\n\n\nColumn Name\nData Type\nRemark\n\n\n\n\ntrj_id\nchr\nTrajectory ID\n\n\ndriving_mode\nchr\nMode of Driving\n\n\nosname\nchr\n\n\n\npingtimestamp\nint\nData Recording Timestamp\n\n\nrawlat\nnum\nLatitude Value (WGS-84)\n\n\nrawlng\nnum\nLongitude Value (WGS-84)\n\n\nspeed\nnum\nSpeed\n\n\nbearing\nint\nBearing\n\n\naccuracy\nnum\nAccuracy\n\n\n\nFrom the above table, it is seen that the pingtimestamp is recorded as int. We need to convert this data to proper datetime format to derive meaningful temporal insights of the data. To do so, we will use as_datetime() function from lubridate package.\n\ndf_trajectories$pingtimestamp &lt;- as_datetime(df_trajectories$pingtimestamp)\n\n\n\n4.3 Importing OpenStreetMap road data for Malaysia, Singapore and Brunei\nThe gis_osm_roads_free_1 dataset, which we downloaded from OpenStreetMap, is in ESRI shapefile format. To use this data in an R-environment, we need to import it as an sf object. We can do this using the st_read() function of the sf package. This function reads the shapefile data and returns an sf object that can be used for further analysis.\n\nosm_road_sf &lt;- st_read(dsn = \"~/IS415-GAA/data/geospatial\", \n                layer = \"gis_osm_roads_free_1\") %&gt;% st_transform(crs = 3414)\n\n\n\n4.4 Importing Singapore Master Plan Planning Subzone boundary data\nThe MP14_SUBZONE_WEB_PL dataset, which we downloaded from data.gov.sg, is in ESRI shapefile format. To use this data in an R-environment, we need to import it as an sf object. We can do this using the st_read() function of the sf package. This function reads the shapefile data and returns an sf object that can be used for further analysis.\n\nmpsz_sf &lt;- st_read(dsn = \"~/IS415-GAA/data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\") %&gt;% st_transform(crs = 3414)\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/khantminnaing/IS415-GAA/data/geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\n\n\n\nReflection\n\n\n\nIn the code chunk above, we use %&gt;% operator is used to pipe the output of st_read() to the st_transform() function. Since the dataset we are using is the Singapore boundary, we need to assign the standard coordinate reference system for Singapore, which is SVY21 (EPSG:3414). st_transform() function transforms the coordinate reference system of the sf object to 3414.\n\n\nAfter importing the dataset, we will plot it to see how it looks. The plot() function is used to plot the geometry of the sf object. The st_geometry() function is used to extract the geometry of the mpsz_sf object.\n\nplot(st_geometry(mpsz_sf))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex01.html#data-wrangling",
    "title": "Take-Home Exercise 01: Spatial Point Patterns Analysis of Grab Trajectories in Singapore",
    "section": "5.0 Data Wrangling",
    "text": "5.0 Data Wrangling\nData wrangling is the process of converting and transforming raw data into a usable form and is carried out prior to conducting any data analysis.\n\n5.1 Extracting Trip Starting Locations and Temporal Data Values from Grab-Posisi dataset\nFirstly, we will extract trip starting locations for all unqiue trajectories in the dataset and store them to a new df named origin_df. We are also interested in obtaining valuable temporal data such as the day of the week, the hour, and the date (yy-mm-dd). To do so, we will use the following functions from lubridate package, and add the newly derived values as columns to origin_df.\n\nwday: allows us to get days component of a date-time\nhour: allows us to get hours component of a date-time\nmday: allows us to parse dates with year, month, and day components\n\n\norigin_df &lt;- df_trajectories %&gt;%\n  group_by(trj_id) %&gt;%\n  arrange(pingtimestamp) %&gt;%\n  filter(row_number()==1) %&gt;% \n  mutate(weekday = wday(pingtimestamp,\n                       label=TRUE,\n                       abbr=TRUE),\n         starting_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n\n\n\n5.2 Extracting Trip Ending Locations and Temporal Data Values from Grab-Posisi dataset\nSimilar to what we did in previous session, we are also interested to extract trip ending locations and associated temporal data into a new df called destination_df. We will use the same functions from previous session here.\n\ndestination_df &lt;- df_trajectories %&gt;%\n  group_by(trj_id) %&gt;%\n  arrange(desc(pingtimestamp)) %&gt;%\n  filter(row_number()==1) %&gt;% \n  mutate(weekday = wday(pingtimestamp,\n                       label=TRUE,\n                       abbr=TRUE),\n         starting_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n\n\n\n\n\n\n\nReflection\n\n\n\narrange() function sort the timestamps in ascending order by default. Hence, this default order is applied to origin_df. However, for destination_df, the arrange(desc()) argument is used to modify the default order to descending.\n\n\n\n\n5.3 Converting to sf tibble data.frame\n\norigin_sf &lt;- st_as_sf(origin_df,\n                      coords = c(\"rawlng\", \"rawlat\"),\n                      crs = 4326) %&gt;%\n  st_transform(crs = 3414)\n\ndestination_sf &lt;- st_as_sf(destination_df,\n                      coords = c(\"rawlng\", \"rawlat\"),\n                      crs = 4326) %&gt;%\n  st_transform(crs = 3414)\n\n\n\n5.4 Creating a CoastalLine of Singapore\nThe original mpsz_sf dataset we imported include information of all URA Master Plan planning area boundaries. However, for this analysis, we only need the national-level boundary of Singapore. Hence, we will need to union all the subzone boundaries to one single polygon boundary. Also, Grab ride-hailing service is only available on the main Singapore islands. Hence, we will need to remove outer islands which Grab service is not available. In particular, we will remove the following planning subzones: NORTH-EASTERN ISLANDS, SOUTHERN GROUP, SUDONG & SEMAKAU.\nWe can remove these subzones using the subset() function. The subset() function is used to extract rows from a data frame that meet certain conditions.\n\nnortheasten.islands &lt;- subset(mpsz_sf, mpsz_sf$SUBZONE_N == \"NORTH-EASTERN ISLANDS\")\nsouthern.islands &lt;- subset(mpsz_sf, mpsz_sf$SUBZONE_N == \"SOUTHERN GROUP\")\nsudong &lt;- subset(mpsz_sf, mpsz_sf$SUBZONE_N == \"SUDONG\")\nsemakau &lt;- subset(mpsz_sf,mpsz_sf$SUBZONE_N == \"SEMAKAU\")\n\nouterislands &lt;- dplyr::bind_rows(list(northeasten.islands,southern.islands,sudong,semakau))\n\n\n\n\n\n\n\nReflection\n\n\n\nIn the code chunk above, we first created four new data frames called northeasten.islands, southern.islands, sudong, and semakau by selecting rows from mpsz_sf where the value in the SUBZONE_N column matches the corresponding value.\nAfter that, we used bind_rows() function from the dplyr package to combine these four data frames into a single data frame called outerislands.\n\n\nAfter importing the dataset, we will plot it to see how it looks.\n\nplot(st_geometry(outerislands))\n\n\n\n\nAs mentioned earlier, we only need to get national-level boundary of Singapore, without outer islands. To do so, we will need to process the mpsz_sf layer to achieve the outcome. - We will first use st_union() function from the sf package to combine the geometries of mpsz_sf and outerislands sf objects into a single geometry each. - Next, we will use st_difference() function then removes the overlapping areas between the two geometries. - Finally, we will store the non-overlapping areas into a new sf objected called sg_sf.\n\nsg_sf &lt;- st_difference(st_union(mpsz_sf), st_union(outerislands))\n\nTo assess whether the geometry of the newly created sg_sf matches our intended outcome, we will plot it out.\n\nplot(st_geometry(sg_sf))\n\n\n\n\n\n\n5.5 Extracting Road Layers within Singapore\nAs we have seen in Section 4.3., osm_road_sf dataset includes road networks from not only Singapore, but also Malaysia and Brunei. However, our analysis is focused on Singapore. Hence, we will need to remove unecessary data rows. To do so, we will\n\nsg_road_sf &lt;- st_intersection(osm_road_sf,sg_sf)\n\nNext, we will look at the classification of road networks as provided by OpenStreetMap.\n\nunique(sg_road_sf$fclass)\n\n [1] \"primary\"        \"residential\"    \"tertiary\"       \"footway\"       \n [5] \"service\"        \"secondary\"      \"motorway\"       \"motorway_link\" \n [9] \"trunk\"          \"trunk_link\"     \"primary_link\"   \"pedestrian\"    \n[13] \"living_street\"  \"unclassified\"   \"steps\"          \"track_grade2\"  \n[17] \"track\"          \"secondary_link\" \"cycleway\"       \"path\"          \n[21] \"tertiary_link\"  \"track_grade1\"   \"track_grade3\"   \"unknown\"       \n[25] \"track_grade5\"   \"bridleway\"      \"track_grade4\"  \n\n\n\ntm_shape(sg_sf) +\n  tm_polygons() +\ntm_shape(sg_road_sf) +\n  tm_lines(col=\"fclass\", palette =\"viridis\") +\n  tm_layout(main.title = \"Road Network in Singapore\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.outside = TRUE,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5)\n\n\n\n5.5 Converting the Simple Features to Planar Point Pattern Object\nIn order to use the capabilities of spatstat packahe, a spatial dataset should be converted into an object of class planar point pattern ppp (Baddeley et al., 2015). A point pattern object contains the spatial coordinates of the points, the marks attached to the points (if any), the window in which the points were observed, and the name of the unit of length for the spatial coordinates. s. Thus, a single object of class ppp contains all the information required to perform spatial point pattern analysis.\nIn previous section, we have created sf objects of Grab trajectory origin and destination points. Now, we will convert them into ppp objects using as.ppp() function from spatstat package.\n\norigin_ppp &lt;- as.ppp(st_coordinates(origin_sf), st_bbox(origin_sf))\n\npar(mar = c(0,0,1,0))\nplot(origin_ppp)\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe code chunk above converts the origin_sf object to a point pattern object of class ppp. st_coordinates() function is used to extract the coordinates of the origin_sf object and st_bbox() function is used to extract the bounding box of the origin_sf object. The resulting object origin_ppp is a point pattern object of class ppp.\n\n\n\ndestination_ppp &lt;- as.ppp(st_coordinates(destination_sf), st_bbox(destination_sf))\n\npar(mar = c(0,0,1,0))\nplot(destination_ppp)\n\n\n\n\n\n\n5.6 Handling Data Errors\nBefore going striaght into analysis, we will need to a quick look at the summary statistics of the newly created ppp objects. This is an important step to ensure that the data is free of errors and that a reliable analysis can be performed.\n\n5.6.1 Data Error Handling for origin_ppp\nWe will use summary() function to get summary information of origin_ppp object.\n\nsummary(origin_ppp)\n\nPlanar point pattern:  28000 points\nAverage intensity 2.473666e-05 points per square unit\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [3628.24, 49845.23] x [25198.14, 49689.64] units\n                    (46220 x 24490 units)\nWindow area = 1131920000 square units\n\n\nWe can also check if there is any duplicated points in origin_ppp object using any(duplicated() function.\n\nany(duplicated(origin_ppp))\n\n[1] FALSE\n\n\nThe code output is FALSE, which means there are no duplication of point coordaintes in the origin_ppp object.\n\nWhy do we need to check duplication?\nWhen analyzing spatial point processes, it is important to avoid duplication of points. This is because statistical methodology for spatial point processes is based largely on the assumption that processes are simple, i.e., that points of the process can never be coincident. When the data have coincident points, some statistical procedures designed for simple point processes will be severely affected (Baddeley et al., 2015).\n\n\n\n5.6.2 Data Error Handling for destination_ppp\nWe will use summary() function to get summary information of destination_ppp object.\n\nsummary(destination_ppp)\n\nPlanar point pattern:  28000 points\nAverage intensity 2.493661e-05 points per square unit\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [3637.21, 49870.63] x [25221.3, 49507.79] units\n                    (46230 x 24290 units)\nWindow area = 1122850000 square units\n\n\nWe can also check if there is any duplicated points in destination_ppp object using any(duplicated() function.\n\nany(duplicated(destination_ppp))\n\n[1] FALSE\n\n\nThe code output is FALSE, which means there are no duplication of point coordinates in the destination_ppp object.\n\n\n\n5.7 Creating Observation Windows\nMany data types in spatstat require us to specify the region of space inside which the data were observed. This is the observation window and it is represented by an object of class owin. In this analysis, our study area is Singapore, hence we will use Singapore boundary as the observation window for spatial point pattern analysis.\nIn Section 5.4, we have already created the sg_sf object, which represents the Singapore boundary (without outer islands). To convert this sf object to owin object, we will use as.owin() function from spatstat package.\n\nsg_owin &lt;- as.owin(sg_sf)\nplot.owin(sg_owin)\n\n\n\n\nWe will use summary() function to get summary information of sg_owin object.\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n44 separate polygons (24 holes)\n                  vertices         area relative.area\npolygon 1            14651  6.97996e+08      9.92e-01\npolygon 2 (hole)         3 -2.21090e+00     -3.14e-09\npolygon 3              285  1.61128e+06      2.29e-03\npolygon 4 (hole)         3 -2.05920e-03     -2.93e-12\npolygon 5 (hole)         3 -8.83647e-03     -1.26e-11\npolygon 6               27  1.50315e+04      2.14e-05\npolygon 7 (hole)        36 -4.01660e+04     -5.71e-05\npolygon 8 (hole)       317 -5.11280e+04     -7.27e-05\npolygon 9 (hole)         3 -2.89050e-05     -4.11e-14\npolygon 10              30  2.80002e+04      3.98e-05\npolygon 11 (hole)        3 -2.83151e-01     -4.03e-10\npolygon 12              71  8.18750e+03      1.16e-05\npolygon 13 (hole)        3 -1.68316e-04     -2.39e-13\npolygon 14 (hole)       36 -7.79904e+03     -1.11e-05\npolygon 15 (hole)        4 -2.05611e-02     -2.92e-11\npolygon 16 (hole)        3 -2.18000e-06     -3.10e-15\npolygon 17 (hole)        3 -3.65501e-03     -5.20e-12\npolygon 18 (hole)        3 -4.95057e-02     -7.04e-11\npolygon 19 (hole)        3 -3.99521e-02     -5.68e-11\npolygon 20 (hole)        3 -6.62377e-01     -9.42e-10\npolygon 21 (hole)        3 -2.09065e-03     -2.97e-12\npolygon 22              91  1.49663e+04      2.13e-05\npolygon 23 (hole)       26 -1.25665e+03     -1.79e-06\npolygon 24 (hole)      349 -1.21433e+03     -1.73e-06\npolygon 25 (hole)       20 -4.39069e+00     -6.24e-09\npolygon 26 (hole)       48 -1.38338e+02     -1.97e-07\npolygon 27 (hole)       28 -1.99862e+01     -2.84e-08\npolygon 28              40  1.38607e+04      1.97e-05\npolygon 29 (hole)       40 -6.00381e+03     -8.54e-06\npolygon 30 (hole)        7 -1.40545e-01     -2.00e-10\npolygon 31 (hole)       12 -8.36709e+01     -1.19e-07\npolygon 32              45  2.51218e+03      3.57e-06\npolygon 33             142  3.22293e+03      4.58e-06\npolygon 34             148  3.10395e+03      4.41e-06\npolygon 35              75  1.73526e+04      2.47e-05\npolygon 36              83  5.28920e+03      7.52e-06\npolygon 37             106  3.04104e+03      4.32e-06\npolygon 38             266  1.50631e+06      2.14e-03\npolygon 39              71  5.63061e+03      8.01e-06\npolygon 40              10  1.99717e+02      2.84e-07\npolygon 41             478  2.06120e+06      2.93e-03\npolygon 42              65  8.42861e+04      1.20e-04\npolygon 43              47  3.82087e+04      5.43e-05\npolygon 44              22  6.74651e+03      9.59e-06\nenclosing rectangle: [2667.54, 55941.94] x [21494.3, 50256.33] units\n                     (53270 x 28760 units)\nWindow area = 703317000 square units\nFraction of frame area: 0.459\n\n\n\n\n5.8 Combining ppp objects and owin object\nIn section 5.5, we have created two ppp objects - origin_ppp and destination_ppp, each representing the spatial points of Grab trajectory origin and destination. In section 5.7, we have created a owin object called sg_owin, which represent the observation window of our analysis.\nThe observation window sg_owin and the point pattern origin_ppp or destination_ppp can be combined, so that the custom window replaces the default ractangular extent (as seen in section 5.5).\n\norigin_ppp_sg = origin_ppp[sg_owin]\ndestination_ppp_sg = destination_ppp[sg_owin]\n\npar(mar = c(0,0,1,0))\nplot(origin_ppp_sg)\n\n\n\nplot(destination_ppp_sg)\n\n\n\n\nWe will use summary() function to get summary information of the newly created origin_ppp_sg object and destination_ppp_sg object.\n\nsummary(origin_ppp_sg)\n\nPlanar point pattern:  28000 points\nAverage intensity 3.981136e-05 points per square unit\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: polygonal boundary\n44 separate polygons (24 holes)\n                  vertices         area relative.area\npolygon 1            14651  6.97996e+08      9.92e-01\npolygon 2 (hole)         3 -2.21090e+00     -3.14e-09\npolygon 3              285  1.61128e+06      2.29e-03\npolygon 4 (hole)         3 -2.05920e-03     -2.93e-12\npolygon 5 (hole)         3 -8.83647e-03     -1.26e-11\npolygon 6               27  1.50315e+04      2.14e-05\npolygon 7 (hole)        36 -4.01660e+04     -5.71e-05\npolygon 8 (hole)       317 -5.11280e+04     -7.27e-05\npolygon 9 (hole)         3 -2.89050e-05     -4.11e-14\npolygon 10              30  2.80002e+04      3.98e-05\npolygon 11 (hole)        3 -2.83151e-01     -4.03e-10\npolygon 12              71  8.18750e+03      1.16e-05\npolygon 13 (hole)        3 -1.68316e-04     -2.39e-13\npolygon 14 (hole)       36 -7.79904e+03     -1.11e-05\npolygon 15 (hole)        4 -2.05611e-02     -2.92e-11\npolygon 16 (hole)        3 -2.18000e-06     -3.10e-15\npolygon 17 (hole)        3 -3.65501e-03     -5.20e-12\npolygon 18 (hole)        3 -4.95057e-02     -7.04e-11\npolygon 19 (hole)        3 -3.99521e-02     -5.68e-11\npolygon 20 (hole)        3 -6.62377e-01     -9.42e-10\npolygon 21 (hole)        3 -2.09065e-03     -2.97e-12\npolygon 22              91  1.49663e+04      2.13e-05\npolygon 23 (hole)       26 -1.25665e+03     -1.79e-06\npolygon 24 (hole)      349 -1.21433e+03     -1.73e-06\npolygon 25 (hole)       20 -4.39069e+00     -6.24e-09\npolygon 26 (hole)       48 -1.38338e+02     -1.97e-07\npolygon 27 (hole)       28 -1.99862e+01     -2.84e-08\npolygon 28              40  1.38607e+04      1.97e-05\npolygon 29 (hole)       40 -6.00381e+03     -8.54e-06\npolygon 30 (hole)        7 -1.40545e-01     -2.00e-10\npolygon 31 (hole)       12 -8.36709e+01     -1.19e-07\npolygon 32              45  2.51218e+03      3.57e-06\npolygon 33             142  3.22293e+03      4.58e-06\npolygon 34             148  3.10395e+03      4.41e-06\npolygon 35              75  1.73526e+04      2.47e-05\npolygon 36              83  5.28920e+03      7.52e-06\npolygon 37             106  3.04104e+03      4.32e-06\npolygon 38             266  1.50631e+06      2.14e-03\npolygon 39              71  5.63061e+03      8.01e-06\npolygon 40              10  1.99717e+02      2.84e-07\npolygon 41             478  2.06120e+06      2.93e-03\npolygon 42              65  8.42861e+04      1.20e-04\npolygon 43              47  3.82087e+04      5.43e-05\npolygon 44              22  6.74651e+03      9.59e-06\nenclosing rectangle: [2667.54, 55941.94] x [21494.3, 50256.33] units\n                     (53270 x 28760 units)\nWindow area = 703317000 square units\nFraction of frame area: 0.459\n\nsummary(destination_ppp_sg)\n\nPlanar point pattern:  27997 points\nAverage intensity 3.980709e-05 points per square unit\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: polygonal boundary\n44 separate polygons (24 holes)\n                  vertices         area relative.area\npolygon 1            14651  6.97996e+08      9.92e-01\npolygon 2 (hole)         3 -2.21090e+00     -3.14e-09\npolygon 3              285  1.61128e+06      2.29e-03\npolygon 4 (hole)         3 -2.05920e-03     -2.93e-12\npolygon 5 (hole)         3 -8.83647e-03     -1.26e-11\npolygon 6               27  1.50315e+04      2.14e-05\npolygon 7 (hole)        36 -4.01660e+04     -5.71e-05\npolygon 8 (hole)       317 -5.11280e+04     -7.27e-05\npolygon 9 (hole)         3 -2.89050e-05     -4.11e-14\npolygon 10              30  2.80002e+04      3.98e-05\npolygon 11 (hole)        3 -2.83151e-01     -4.03e-10\npolygon 12              71  8.18750e+03      1.16e-05\npolygon 13 (hole)        3 -1.68316e-04     -2.39e-13\npolygon 14 (hole)       36 -7.79904e+03     -1.11e-05\npolygon 15 (hole)        4 -2.05611e-02     -2.92e-11\npolygon 16 (hole)        3 -2.18000e-06     -3.10e-15\npolygon 17 (hole)        3 -3.65501e-03     -5.20e-12\npolygon 18 (hole)        3 -4.95057e-02     -7.04e-11\npolygon 19 (hole)        3 -3.99521e-02     -5.68e-11\npolygon 20 (hole)        3 -6.62377e-01     -9.42e-10\npolygon 21 (hole)        3 -2.09065e-03     -2.97e-12\npolygon 22              91  1.49663e+04      2.13e-05\npolygon 23 (hole)       26 -1.25665e+03     -1.79e-06\npolygon 24 (hole)      349 -1.21433e+03     -1.73e-06\npolygon 25 (hole)       20 -4.39069e+00     -6.24e-09\npolygon 26 (hole)       48 -1.38338e+02     -1.97e-07\npolygon 27 (hole)       28 -1.99862e+01     -2.84e-08\npolygon 28              40  1.38607e+04      1.97e-05\npolygon 29 (hole)       40 -6.00381e+03     -8.54e-06\npolygon 30 (hole)        7 -1.40545e-01     -2.00e-10\npolygon 31 (hole)       12 -8.36709e+01     -1.19e-07\npolygon 32              45  2.51218e+03      3.57e-06\npolygon 33             142  3.22293e+03      4.58e-06\npolygon 34             148  3.10395e+03      4.41e-06\npolygon 35              75  1.73526e+04      2.47e-05\npolygon 36              83  5.28920e+03      7.52e-06\npolygon 37             106  3.04104e+03      4.32e-06\npolygon 38             266  1.50631e+06      2.14e-03\npolygon 39              71  5.63061e+03      8.01e-06\npolygon 40              10  1.99717e+02      2.84e-07\npolygon 41             478  2.06120e+06      2.93e-03\npolygon 42              65  8.42861e+04      1.20e-04\npolygon 43              47  3.82087e+04      5.43e-05\npolygon 44              22  6.74651e+03      9.59e-06\nenclosing rectangle: [2667.54, 55941.94] x [21494.3, 50256.33] units\n                     (53270 x 28760 units)\nWindow area = 703317000 square units\nFraction of frame area: 0.459"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01.html#exploratory-spatial-data-analysis",
    "href": "Take-home_Ex/Take-home_Ex01.html#exploratory-spatial-data-analysis",
    "title": "Take-Home Exercise 01: Spatial Point Patterns Analysis of Grab Trajectories in Singapore",
    "section": "6.0 Exploratory Spatial Data Analysis",
    "text": "6.0 Exploratory Spatial Data Analysis\n\n6.1 Visualising Frequency Distribution\n\norigin_day &lt;- ggplot(data=origin_df, \n              aes(x=weekday)) + \n              geom_bar()\n\ndestination_day &lt;-  ggplot(data=destination_sf, \n                    aes(x=weekday)) + \n                    geom_bar()\n\norigin_day + destination_day\n\n\n\n\n\n\n6.2 Creating Point Symbol Maps\n\ntmap_mode(\"view\")\ntm_shape(origin_sf) +\n    tm_dots(alpha=0.4, \n          size=0.05)\n\ntm_shape(destination_sf) +\n    tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n6.2 Measuring Central Tendency\nDescriptive statistics are used in point pattern analysis to summarise a point pattern’s basic properties, such as its central tendency and dispersion. The mean centre and the median centre are two often employed metrics for central tendency (Gimond, 2019).\n\n6.2.1 Mean Center\nMean center is the arithmetic average of the (x, y) coordinates of all point in the study area. Similar to mean in statistical analysis, mean center is influenced to a greater degree by the outliers. (Yuan et al.,2020)\n\norigin_xy &lt;- st_coordinates(origin_sf)\norigin_mc &lt;- apply(origin_xy, 2, mean)\n\ndestination_xy &lt;- st_coordinates(destination_sf)\ndestination_mc &lt;- apply(destination_xy, 2, mean)\n\norigin_mc\n\n       X        Y \n28490.57 36939.04 \n\ndestination_mc\n\n       X        Y \n28870.96 36590.49 \n\n\nThe results show that the origin and destination mean centres are, respectively, (28490.57, 36939.04) and (28870.96, 36590.49). The two mean centres appear to be situated in close proximity to one another.\n\n\n6.2.2 Median Center\nMedian center is the location that minimizes the sum of distances required to travel to all points within an observation window. It can be calculated using an iterative procedure first presented by Kulin and Kuenne (1962). The procedure begins at a predetermined point, such as the median center, as the initial point. Then, the algorithm updates the median center’s new coordinates (x’, y’) continually until the optimal value is reached. The median center, as opposed to the mean center, offers a more reliable indicator of central tendency as it is unaffected by outliers (Yuan et al., 2020).\n\norigin_medc &lt;- apply(origin_xy, 2, median)\n\ndestination_medc &lt;- apply(destination_xy, 2, median)\n\norigin_medc\n\n       X        Y \n28553.17 36179.05 \n\ndestination_medc\n\n       X        Y \n28855.04 35883.86 \n\n\nBased on the results, the median centres of origin and destination are, respectively, (28553.17, 36179.05) and (28855.04, 35883.86). The two median centres appear to be situated in close proximity to one another.\nMoreover, mean centers and median centers for each origin and destination points are similar. This may imply that the distribution of the data is relatively balanced and there is not a significant difference in the spatial patterns between the origin and destination points. Additionally, this indicates that both the mean center and median center are effective measures for analyzing the central tendency of the data in this context.\n\n\n6.2.3 Plotting Mean and Median Centers\nWe can try to plot both results obtained from previous section on the same plane for better comparison of the mean center and median center.\n\npar(mar = c(0,0,1,0))\n\nplot(sg_sf, col='light grey', main=\"mean and median centers of origin_sf\")\npoints(origin_xy, cex=.5)\npoints(cbind(origin_mc[1], origin_mc[2]), pch='*', col='red', cex=3)\npoints(cbind(origin_medc[1], origin_medc[2]), pch='*', col='purple', cex=3)\n\n\n\n\n\npar(mar = c(0,0,1,0))\n\nplot(sg_sf, col='light grey', main=\"mean and median centers of destination_sf\")\npoints(destination_xy, cex=.5)\npoints(cbind(destination_mc[1], destination_mc[2]), pch='*', col='yellow', cex=3)\npoints(cbind(destination_medc[1], destination_medc[2]), pch='*', col='orange', cex=3)\n\n\n\n\n\n\n\n6.2 Measuring Dispersion\n\n6.2.1 Standard Distance\nStandard distances are defined similarly to standard deviations. This indicator measures how dispersed a group of points is around its mean center (Gimond, 2023).\n\norigin_sd &lt;- sqrt(sum((origin_xy[,1] - origin_mc[1])^2 + (origin_xy[,2] - origin_mc[2])^2) / nrow(origin_xy))\n\ndestination_sd &lt;- sqrt(sum((destination_xy[,1] - destination_mc[1])^2 + (destination_xy[,2] - destination_mc[2])^2) / nrow(destination_xy))\n\norigin_sd\n\n[1] 10187.88\n\ndestination_sd\n\n[1] 9545.69\n\n\nFrom the results, the origin and destination standard distances are 10187.88 and 9545.69, respectively. Hence, it appears that origin points are more dispersed than the origin points.\n\n\n\n\n\n\nReflection\n\n\n\nHowever, it would be challenging to discern why the origin points are more dispersed without further analysis. Further analysis would be needed to determine the factors contributing to the increased dispersion of destination points. Since it is out of scope for this exercise, we will not explore any further.\n\n\n\n\n6.2.3 Plotting Standard Distances\nIn this section, we will create bearing circles of origin and destination points using the standard distance values we have calculated earlier. This can provide visual representation of their dispersion and make intuitive comparison between them.\n\npar(mar = c(0,0,1,0))\nplot(sg_sf, col='light grey', main=\"standard distance of origin_sf\")\npoints(origin_xy, cex=.5)\npoints(cbind(origin_mc[1], origin_mc[2]), pch='*', col='red', cex=3)\n\nbearing &lt;- 1:360 * pi/180\ncx &lt;- origin_mc[1] + origin_sd * cos(bearing)\ncy &lt;- origin_mc[2] + origin_sd * sin(bearing)\ncircle &lt;- cbind(cx, cy)\nlines(circle, col='red', lwd=2)\n\n\n\n\n\npar(mar = c(0,0,1,0))\nplot(sg_sf, col='light grey',main=\"standard distance of destination_sf\")\npoints(destination_xy, cex=.5)\npoints(cbind(destination_mc[1], destination_mc[2]), pch='*', col='purple', cex=3)\n\nbearing &lt;- 1:360 * pi/180\ncx &lt;- destination_mc[1] + destination_sd * cos(bearing)\ncy &lt;- destination_mc[2] + destination_sd * sin(bearing)\ncircle &lt;- cbind(cx, cy)\nlines(circle, col='purple', lwd=2)\n\n\n\n\nA better comparison of the standard distances between origin and destination points can also be achieved by trying to plot both results on the same plane.\n\npar(mar = c(0,0,1,0))\n\nplot(sg_sf, col='light grey',main=\"standard distances of origin_sf & destination_sf\")\npoints(cbind(origin_mc[1], origin_mc[2]), pch='*', col='red', cex=3)\npoints(cbind(destination_mc[1], destination_mc[2]), pch='*', col='purple', cex=3)\n\nbearing &lt;- 1:360 * pi/180\n\norigin_cx &lt;- origin_mc[1] + origin_sd * cos(bearing)\norigin_cy &lt;- origin_mc[2] + origin_sd * sin(bearing)\n\ndestination_cx &lt;- destination_mc[1] + destination_sd * cos(bearing)\ndestination_cy &lt;- destination_mc[2] + destination_sd * sin(bearing)\n\norigin_circle &lt;- cbind(origin_cx, origin_cy)\ndestination_circle &lt;- cbind(destination_cx, destination_cy)\n\nlines(origin_circle, col='red', lwd=2)\nlines(destination_circle, col='purple', lwd=2)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01.html#first-order-spatial-point-patterns-analysis",
    "href": "Take-home_Ex/Take-home_Ex01.html#first-order-spatial-point-patterns-analysis",
    "title": "Take-Home Exercise 01: Spatial Point Patterns Analysis of Grab Trajectories in Singapore",
    "section": "7.0 First-Order Spatial Point Patterns Analysis",
    "text": "7.0 First-Order Spatial Point Patterns Analysis\nAfter data wrangling is complete, we will start to perform first-order spatial point pattern analysis using functions from spatstat package. As we have discussed in Section 2.0., First-order properties concern the characteristics of individual point locations and their variations of their density across space and are mostly addressed by density-based techniques, such as quadrant analysis and kernel density estimation.\nInvestigation of the intensity of a point pattern is one of the first and most important steps in point pattern analysis (Baddeley et al., 2015). If the point process has an intensity function λ(u), this function can be estimated non-parametrically by kernel estimation (Baddeley et al., 2015). Kernel estimation allows for smoothing of the probability density estimation of a random variable (in this analysis a point event) based on kernels as weights.\n\n7.1 Rescaling origin_ppp_sg and destination_ppp_sg\nThe SVY21 Coordinate References System uses meters as the standard unit. Hence, the original_ppp_sg and destination_ppp_sg that we have prepared in the previous sections has “metres” as the unit. However, we will need to convert the measuring unit from metre to kilometeres when calculating the kernel density estimators for entirety of Singapore because kilometers provide a more appropriate scale for analyzing large areas.\n\norigin_ppp_sg.km &lt;- rescale(origin_ppp_sg, 1000, \"km\")\ndestination_ppp_sg.km &lt;- rescale(destination_ppp_sg, 1000, \"km\")\n\n\n\n7.2 Computing Kernel Density Estimation\nKernel Destiny Estimation (KDE) generates a surface (raster) representing the estimated distribution of point events over the observation window. Each cell in the KDE layer carries a value representing the estimated density of that location (Wilkin, 2020). Hence, this approach is also known as local density approach.\nTo build the KDE layer, a localised density is calculated for multiple small subsets of the observation window. However, these subsets overlap throughout each iteration, resulting in a moving window defined by a kernel (Wilkin, 2020; Gimond, 2023).\nKernel estimation is implemented in spatstat by the function density.ppp(), a method for the generic command density.\n\npar(mar = c(0,1,1,1))\nkde_default_origin &lt;- density(origin_ppp_sg.km)\nplot(kde_default_origin,main = \"Default Density KDE for Origin Points\")\ncontour(kde_default_origin, add=TRUE)\n\n\n\n\n\npar(mar = c(0,1,1,1))\nkde_default_destination &lt;- density(destination_ppp_sg.km)\nplot(kde_default_destination,main = \"Default Density KDE for Destination Points\")\ncontour(kde_default_destination, add=TRUE)\n\n\n\n\nHowever, the KDE given by default argument may not be what we aim to achieve. In this regards, we can specify smoothing bandwidth through the argument sigma or kernel function through the argument kernel.\n\n\n7.2 Bandwidth Selection\nThe kernel bandwidth sigma controls the degree of smoothing. In general, a small value of sigma produces an irregular intensity surface, while a large value of sigma appears to oversmooth the intensity.\n\n\n\nDensity Estimates with Different Smoothing Bandwidth (Ref, Baddeley et al., 2015)\n\n\n\n7.2.1 Fixed Bandwidth\ndensity() function of spatstat allows us to compute a kernel density for a given set of point events.\n\nbw.diggle() (Cross Validated) assumes a Cox process, which is more clustered (positively correlated) than a Poisson process;\nbw.CvL() (Cronie and van Lieshout’s Criterion)\nbw.scott() (Scott’s Rule of Thumb)\nbw.ppl() (Likelihood Cross Validation) assumes an inhomogeneous Poisson process\n\n\nbw_diggle &lt;- bw.diggle(origin_ppp_sg.km)\nbw_diggle\n\n      sigma \n0.008300264 \n\nbw_CvL &lt;- bw.CvL(origin_ppp_sg.km)\nbw_CvL\n\n   sigma \n3.147562 \n\nbw_scott &lt;- bw.scott(origin_ppp_sg.km)\nbw_scott\n\n  sigma.x   sigma.y \n1.5926707 0.9389324 \n\nbw_ppl &lt;- bw.ppl(origin_ppp_sg.km)\nbw_ppl\n\n    sigma \n0.1238744 \n\nbw_frac &lt;- bw.frac(sg_owin)\nbw_frac\n\n[1] 9196.392\n\n\nThe commands used for generating bandwidth return a numerical value, the optimised bandwidth, which also belongs to the special class bw.optim. The plot method for this class shows the objective function for the optimisation that leads to the result.\n\npar(mfrow = c(1,2))\nplot(bw_diggle, xlim=c(-0.02,0.05), ylim=c(-60,200))\nplot(bw_CvL)\n\n\n\npar(mfrow = c(1,2))\nplot(bw_scott)\nplot(bw_ppl,  xlim=c(-1,5), ylim=c(70000,130000))\n\n\n\n\n\nkde_diggle &lt;- density(origin_ppp_sg.km, bw_diggle)\nkde_CvL &lt;- density(origin_ppp_sg.km, bw_CvL)\nkde_scott &lt;- density(origin_ppp_sg.km, bw_scott)\nkde_ppl &lt;- density(origin_ppp_sg.km, bw_ppl)\n\npar(mar = c(1,1,1,1.5),mfrow = c(2,2))\nplot(kde_diggle,main = \"kde_diggle\")\nplot(kde_CvL,main = \"kde_CvL\")\nplot(kde_scott,main = \"kde_scott\")\nplot(kde_ppl,main = \"kde_ppl\")\n\n\n\n\n\nnames(kde_diggle)\n\n [1] \"v\"      \"dim\"    \"xrange\" \"yrange\" \"xstep\"  \"ystep\"  \"xcol\"   \"yrow\"  \n [9] \"type\"   \"units\" \n\n\n\npar(mar = c(1,1,1,1.5),mfrow = c(2,2))\nhist(kde_diggle,main = \"kde_diggle\")\nhist(kde_CvL,main = \"kde_CvL\")\nhist(kde_scott,main = \"kde_scott\")\nhist(kde_ppl,main = \"kde_ppl\")\n\n\n\n\n$SE is used to extract the standard error of the density estimate from the output of the density() function\n\ndse_diggle &lt;- density(origin_ppp_sg.km, bw_diggle, se=TRUE)$SE\ndse_CvL &lt;- density(origin_ppp_sg.km, bw_CvL, se=TRUE)$SE\ndse_scott &lt;- density(origin_ppp_sg.km, bw_scott, se=TRUE)$SE\ndse_ppl &lt;- density(origin_ppp_sg.km, bw_ppl, se=TRUE)$SE\n\n\npar(mar = c(1,1,1,1.5),mfrow = c(2,2))\nplot(dse_diggle,main = \"standard deviation_diggle\")\nplot(dse_CvL,main = \"standard deviation_CvL\")\nplot(dse_scott,main = \"standard deviation_scott\")\nplot(dse_ppl,main = \"standard deviation_ppl\")\n\n\n\n\n\npar(mar = c(0,1,1,1))\nkde_scott &lt;- density(origin_ppp_sg.km, bw_scott)\nplot(kde_scott,main = \"bw_scott KDE for Origin Points\")\ncontour(kde_scott, add=TRUE)\n\n\n\nkde_scott_dse &lt;- density(origin_ppp_sg.km, bw_scott, se=TRUE)$SE\nplot(kde_scott_dse,main = \"Standard Deviation\")\ncontour(kde_scott_dse, add=TRUE)\n\n\n\n\nNot very smooth, rounded the value to nearest full number.\n\npar(mar = c(0,1,1,1))\nkde_2km &lt;- density(origin_ppp_sg.km, sigma=2)\nplot(kde_2km,main = \"2-km Bandwidth KDE for Origin Points\")\ncontour(kde_2km, add=TRUE)\n\n\n\nkde_2km_dse &lt;- density(origin_ppp_sg.km, sigma=2, se=TRUE)$SE\nplot(kde_2km_dse,main = \"Standard Deviation\")\ncontour(kde_2km_dse, add=TRUE)\n\n\n\n\n\nhist(kde_2km,main = \"kde_2km\")\n\n\n\n\n\n\n7.2.2 Spatially Adaptive Bandwidth\nA fixed smoothing bandwidth is unsatisfactory if the true intensity varies greatly across the spatial domain, because it is likely to cause over-smoothing in the high-intensity areas and under-smoothing in the low intensity areas (Baddeley et al., 2015)\nThe fixed bandwidth method is very sensitive to highly skewed distribution of spatial point patterns over geographical units.\n\nkde_origin_adaptive &lt;- adaptive.density(origin_ppp_sg.km, method = \"kernel\")\n\n\npar(mar = c(0,1,1,1))\nplot(kde_origin_adaptive,main = \"adapative kernel density\")\n\n\n\n\n\nraster_kde_scott &lt;- raster(kde_scott)\nraster_kde_adaptive &lt;- raster(kde_origin_adaptive)\nraster_kde_scott\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4162063, 0.2247034  (x, y)\nextent     : 2.667538, 55.94194, 21.4943, 50.25633  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : 4.59428e-11, 186.6852  (min, max)\n\n\n\nprojection(raster_kde_scott) &lt;- CRS(\"+init=EPSG:3414 +units=km\")\nprojection(raster_kde_adaptive) &lt;- CRS(\"+init=EPSG:3414 +units=km\")\n\n\ntmap_mode('view')\ntm_basemap(server = \"OpenStreetMap.HOT\") +\n  tm_basemap(server = \"Esri.WorldImagery\") +\n  tm_shape(raster_kde_scott) +\n  tm_raster(\"layer\",\n            n = 5,\n            title = \"KDE_scott\",\n            alpha = 0.6,\n            palette = c(\"#ffd51c\",\"#fd953b\",\"#f02a75\",\"#b62385\",\"#021c9e\")) +\n  tm_shape(mpsz_sf)+\n  tm_polygons(alpha=0.1,id=\"PLN_AREA_N\")+\n  tmap_options(check.and.fix = TRUE)\n\n\n\n\n\n\n\ntmap_mode('view')\ntm_basemap(server = \"OpenStreetMap.HOT\") +\n  tm_basemap(server = \"Esri.WorldImagery\") +\n  tm_shape(raster_kde_adaptive) +\n  tm_raster(\"layer\",\n            n = 5,\n            title = \"KDE_Adaptive\",\n            style = \"pretty\",\n            alpha = 0.6,\n            palette = c(\"#ffd51c\",\"#fd953b\",\"#f02a75\",\"#b62385\",\"#021c9e\")) +\n  tm_shape(mpsz_sf)+\n  tm_polygons(alpha=0.1,id=\"PLN_AREA_N\")+\n  tmap_options(check.and.fix = TRUE)\n\n\n\n\n\n\n\nkde_destination_adaptive &lt;- adaptive.density(destination_ppp_sg.km, method = \"kernel\")\n\npar(mar = c(0,1,1,1))\nplot(kde_destination_adaptive,main = \"adapative kernel density for destination points\")\n\n\n\n\n\nkde_destination_diggle &lt;- density(destination_ppp_sg.km, bw_diggle)\nkde_destination_CvL &lt;- density(destination_ppp_sg.km, bw_CvL)\nkde_destination_scott &lt;- density(destination_ppp_sg.km, bw_scott)\nkde_destination_ppl &lt;- density(destination_ppp_sg.km, bw_ppl)\n\npar(mar = c(1,1,1,1.5),mfrow = c(2,2))\nplot(kde_destination_diggle,main = \"kde_destination_diggle\")\nplot(kde_destination_CvL,main = \"kde_destination_CvL\")\nplot(kde_destination_scott,main = \"kde_destination_scott\")\nplot(kde_destination_ppl,main = \"kde_destination_ppl\")\n\n\n\n\n\nraster_kde_destination_scott &lt;- raster(kde_destination_scott)\nraster_kde_destination_adaptive &lt;- raster(kde_destination_adaptive)\n\nprojection(raster_kde_destination_scott) &lt;- CRS(\"+init=EPSG:3414 +units=km\")\nprojection(raster_kde_destination_adaptive) &lt;- CRS(\"+init=EPSG:3414 +units=km\")\n\n\ntmap_mode('view')\ntm_basemap(server = \"OpenStreetMap.HOT\") +\n  tm_basemap(server = \"Esri.WorldImagery\") +\n  tm_shape(raster_kde_destination_scott) +\n  tm_raster(\"layer\",\n            n = 5,\n            title = \"KDE_scott\",\n            alpha = 0.6,\n            palette = c(\"#ffd51c\",\"#fd953b\",\"#f02a75\",\"#b62385\",\"#021c9e\")) +\n  tm_shape(mpsz_sf)+\n  tm_polygons(alpha=0.1,id=\"PLN_AREA_N\")+\n  tmap_options(check.and.fix = TRUE)\n\n\n\n\n\ntmap_mode('plot')\n\n\ntmap_mode('view')\ntm_basemap(server = \"OpenStreetMap.HOT\") +\n  tm_basemap(server = \"Esri.WorldImagery\") +\n  tm_shape(raster_kde_destination_adaptive) +\n  tm_raster(\"layer\",\n            n = 5,\n            title = \"KDE_scott\",\n            alpha = 0.6,\n            palette = c(\"#ffd51c\",\"#fd953b\",\"#f02a75\",\"#b62385\",\"#021c9e\")) +\n  tm_shape(mpsz_sf)+\n  tm_polygons(alpha=0.1,id=\"PLN_AREA_N\")+\n  tmap_options(check.and.fix = TRUE)\n\n\n\n\n\ntmap_mode('plot')\n\n\n\n\n7.4 Planning Area-Level Kernel Density Estimation\n\nwl= mpsz_sf %&gt;% filter(PLN_AREA_N == \"WOODLANDS\")\nje = mpsz_sf %&gt;% filter(PLN_AREA_N == \"JURONG EAST\")\njw = mpsz_sf %&gt;% filter(PLN_AREA_N == \"JURONG WEST\")\ntp = mpsz_sf %&gt;% filter(PLN_AREA_N == \"TAMPINES\")\n\npar(mar = c(1,1,2,0),mfrow=c(2,2))\nplot(st_geometry(wl), main = \"Punggol\")\nplot(st_geometry(je), main = \"Jurong East\")\nplot(st_geometry(jw), main = \"Jurong West\")\nplot(st_geometry(tp), main = \"Tampines\")\n\n\n\n\n\nwl_owin = as.owin(wl)\nje_owin = as.owin(je)\njw_owin = as.owin(jw)\ntp_owin = as.owin(tp)\n\norigin_wl_ppp = origin_ppp_sg[wl_owin]\norigin_je_ppp = origin_ppp_sg[je_owin]\norigin_jw_ppp = origin_ppp_sg[jw_owin]\norigin_tp_ppp = origin_ppp_sg[tp_owin]\n\n\nwl_kde_scott &lt;- density(origin_wl_ppp, sigma=bw.scott, main=\"Woodlands\")\nje_kde_scott &lt;- density(origin_je_ppp, sigma=bw.scott, main=\"Jurong East\")\njw_kde_scott &lt;- density(origin_jw_ppp, sigma=bw.scott, main=\"Jurong West\")\ntp_kde_scott &lt;- density(origin_tp_ppp, sigma=bw.scott, main=\"Tampines\")\n\npar(mar = c(1,1,1,1.5),mfrow = c(2,2))\n\nplot(wl_kde_scott,main = \"KDE Woodlands\")\ncontour(wl_kde_scott, add=TRUE)\nplot(je_kde_scott,main = \"KDE Jurong East\")\ncontour(je_kde_scott, add=TRUE)\nplot(jw_kde_scott,main = \"KDE Jurong West\")\ncontour(jw_kde_scott, add=TRUE)\nplot(tp_kde_scott,main = \"KDE Tampines\")\ncontour(tp_kde_scott, add=TRUE)\n\n\n\n\n\n\n7.0 Spatial Randomness Test\nClark and Evans (1954) give a very simple test of spatial randomness called Clark and Evans aggregation index (R). It is the ratio of the observed mean nearest neighbour distance in the pattern to that expected for a Poisson point process of the same intensity. A value R&gt;1 suggests ordering, while R&lt;1 suggests clustering.\nwe will perform the Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test() of statspat.\nThe test hypotheses are:\n\nH0 = The distribution of trajectory original points are randomly distributed.\nH1= The distribution of trajectory original points are not randomly distributed.\n\nThe 95% confidence interval will be used.\n\nclarkevans.test(origin_ppp_sg,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  origin_ppp_sg\nR = 0.27464, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nThe test hypotheses are:\n\nH0 = The distribution of trajectory destination points are randomly distributed.\nH1= The distribution of trajectory destination points are not randomly distributed.\n\nThe 95% confidence interval will be used.\n\nclarkevans.test(destination_ppp_sg,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  destination_ppp_sg\nR = 0.29544, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01.html#network-constrained-kernel-density-estimation-nkde",
    "href": "Take-home_Ex/Take-home_Ex01.html#network-constrained-kernel-density-estimation-nkde",
    "title": "Take-Home Exercise 01: Spatial Point Patterns Analysis of Grab Trajectories in Singapore",
    "section": "8.0 Network Constrained Kernel Density Estimation (NKDE)",
    "text": "8.0 Network Constrained Kernel Density Estimation (NKDE)\nMany real world point event are not randomly distributed. Their distribution, on the other hand, are constrained by network such as roads, rivers, and fault lines just to name a few of them."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01.html#temporal-network-kernel-density-estimation-tnkde",
    "href": "Take-home_Ex/Take-home_Ex01.html#temporal-network-kernel-density-estimation-tnkde",
    "title": "Take-Home Exercise 01: Spatial Point Patterns Analysis of Grab Trajectories in Singapore",
    "section": "9.0 Temporal Network Kernel Density Estimation (TNKDE)",
    "text": "9.0 Temporal Network Kernel Density Estimation (TNKDE)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01.html#references",
    "href": "Take-home_Ex/Take-home_Ex01.html#references",
    "title": "Take-Home Exercise 01: Spatial Point Patterns Analysis of Grab Trajectories in Singapore",
    "section": "References",
    "text": "References\nBaddeley, A., Rubak, E., & Turner, R. (2015). Spatial Point Patterns: Methodology and Applications with R (1st ed.). Chapman and Hall/CRC. https://doi.org/10.1201/b19708.\nBoots, B.N., & Getis, A. (1988). Point Pattern Analysis. Reprint. Edited by G.I. Thrall. WVU Research Repository.\nFloch, J.-M., Marcon, E., Puech, F. (n.d.). Spatial distribution of points. In M.-P. de Bellefon (Ed.), Handbook of Spatial Analysis : Theory and Application with R (pp. 72–111). Insee-Eurostat.\nGimond (2023). Chapter 11 Point Pattern Analysis. Retrieved from https://mgimond.github.io/Spatial/index.html.\nPebesma, E.; Bivand, R. (2023). Spatial Data Science: With Applications in R (1st ed.). Chapman and Hall/CRC. https://doi.org/10.1201/9780429459016.\nRey, S.J., Arribas-Bel, D., Wolf, L.J. (2023). Point Pattern Analysis. In: Geographic Data Science with python. CRC Press.\nWilkin, J. (2020). Geocomputation 2020-2021 Work Book. University College London. Retrieved from https://jo-wilkin.github.io/GEOG0030/coursebook/analysing-spatial-patterns-iii-point-pattern-analysis.html.\nYuan, Y., Qiang, Y., Bin Asad, K., and Chow, T. E. (2020). Point Pattern Analysis. In J.P. Wilson (Ed.), The Geographic Information Science & Technology Body of Knowledge (1st Quarter 2020 Edition). DOI: 10.22224/gistbok/2020.1.13.\nKam, T. S. (2022). R for Geospatial Data Science and Analytics. Retrieved from https://r4gdsa.netlify.app/"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03-NKDE.html",
    "href": "In-class_Ex/In-class_Ex03-NKDE.html",
    "title": "In-Class Exercise 03 NKDE",
    "section": "",
    "text": "Network constrained Spatial Point Patterns Analysis (NetSPAA) is a collection of spatial point patterns analysis methods special developed for analysing spatial point event occurs on or alongside network. The spatial point event can be locations of traffic accident or childcare centre for example. The network, on the other hand can be a road network or river network.\nIn this hands-on exercise, you are going to gain hands-on experience on using appropriate functions of spNetwork package:\n\nto derive network constrained kernel density estimation (NetKDE), and\nto perform network G-function and k-function analysis"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03-NKDE.html#overview",
    "href": "In-class_Ex/In-class_Ex03-NKDE.html#overview",
    "title": "In-Class Exercise 03 NKDE",
    "section": "",
    "text": "Network constrained Spatial Point Patterns Analysis (NetSPAA) is a collection of spatial point patterns analysis methods special developed for analysing spatial point event occurs on or alongside network. The spatial point event can be locations of traffic accident or childcare centre for example. The network, on the other hand can be a road network or river network.\nIn this hands-on exercise, you are going to gain hands-on experience on using appropriate functions of spNetwork package:\n\nto derive network constrained kernel density estimation (NetKDE), and\nto perform network G-function and k-function analysis"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03-NKDE.html#installing-and-launching-the-r-package",
    "href": "In-class_Ex/In-class_Ex03-NKDE.html#installing-and-launching-the-r-package",
    "title": "In-Class Exercise 03 NKDE",
    "section": "2.0 Installing and launching the R package",
    "text": "2.0 Installing and launching the R package\nIn this hands-on exercise, four R packages will be used, they are:\n\nspNetwork, which provides functions to perform Spatial Point Patterns Analysis such as kernel density estimation (KDE) and K-function on network. It also can be used to build spatial matrices (‘listw’ objects like in ‘spdep’ package) to conduct any kind of traditional spatial analysis with spatial weights based on reticular distances.\nrgdal, which provides bindings to the ‘Geospatial’ Data Abstraction Library (GDAL) (&gt;= 1.11.4) and access to projection/transformation operations from the PROJ library. In this exercise, rgdal will be used to import geospatial data in R and store as sp objects.\nsp, which provides classes and methods for dealing with spatial data in R. In this exercise, it will be used to manage SpatialPointsDataFrame and SpatiaLinesDataFrame, and for performing projection transformation.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\n\npacman::p_load(sf, spNetwork, tmap, classInt, virdis, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03-NKDE.html#importing-data-to-r-environment",
    "href": "In-class_Ex/In-class_Ex03-NKDE.html#importing-data-to-r-environment",
    "title": "In-Class Exercise 03 NKDE",
    "section": "3.0 Importing Data to R Environment",
    "text": "3.0 Importing Data to R Environment\nIn this study, we will analyse the spatial distribution of childcare centre in Punggol planning area. For the purpose of this study, two geospatial data sets will be used. They are:\n\nPunggol_St, a line features geospatial data which store the road network within Punggol Planning Area.\nPunggol_CC, a point feature geospatial data which store the location of childcare centres within Punggol Planning Area.\n\nBoth data sets are in ESRI shapefile format.\n\nnetwork &lt;- st_read(dsn=\"../data/geospatial\", \n                   layer=\"Punggol_St\")\n\nReading layer `Punggol_St' from data source \n  `/Users/khantminnaing/IS415-GAA/data/geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\n\nchildcare &lt;- st_read(dsn=\"../data/geospatial\",\n                     layer=\"Punggol_CC\")\n\nReading layer `Punggol_CC' from data source \n  `/Users/khantminnaing/IS415-GAA/data/geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\n\n\nNext, we will plot the childcare locations (as points) and road network (as lines) as follows.\n\ntmap_mode('view')\ntm_shape(childcare)+\n  tm_dots(col='orange')+\n  tm_shape(network)+\n  tm_lines()\n\n\n\n\n\ntmap_mode('plot')"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03-NKDE.html#network-constrained-kde-netkde-analysis",
    "href": "In-class_Ex/In-class_Ex03-NKDE.html#network-constrained-kde-netkde-analysis",
    "title": "In-Class Exercise 03 NKDE",
    "section": "4.0 Network Constrained KDE (NetKDE) Analysis",
    "text": "4.0 Network Constrained KDE (NetKDE) Analysis\n\n4.1 Preparing the lixels objects\nBefore computing NetKDE, the SpatialLines object need to be cut into lixels with a specified minimal distance. This task can be performed by using with lixelize_lines() of spNetwork as shown in the code chunk below.\n\n\nlixels &lt;- lixelize_lines(network, 750, mindist = 375)\n\n\n\n4.2 Generating Line Centers\nNext, we will used lines_center() of spNetwork to generate a SpatialPointsDataFrame (i.e. samples) with line centre points.\n\nsamples &lt;- lines_center(lixels)\n\n\n\n4.3 Performing NKDE\nOnce we have obtained all the datasets required, we can perform NKDE by using nkde() function of spNetwork.\n\ndensities &lt;- nkde(network, \n                  events = childcare,\n                  w = rep(1,nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5,\n                  sparse = TRUE,\n                  verbose = FALSE)\n\n\n\n4.4 Visualisation\n\nsamples$density &lt;- densities\nlixels$density &lt;- densities\n\nNext, we will rescale the density values to help with better mapping results\n\nsamples$density &lt;- samples$density*1000\nlixels$density &lt;- lixels$density*1000\n\n\ntmap_mode('view')\ntm_shape(lixels)+\n  tm_lines(col=\"density\", palette=\"plasma\")+\ntm_shape(childcare)+\n  tm_dots()\n\n\n\n\n\ntmap_mode('plot')\n\nThe interactive map above effectively reveals road segments (darker color) with relatively higher density of childcare centres than road segments with relatively lower density of childcare centres (lighter color)\nIn practical use, we can use these results to effectively identify areas where new pedestrian roads can be built."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03.html",
    "title": "In-Class Exercise 03",
    "section": "",
    "text": "pacman::p_load(arrow,lubridate,tidyverse,tmap,sf)\n\n\ninstall.packages(\"maptools\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03.html#importing-datasets-to-r-environment",
    "href": "In-class_Ex/In-class_Ex03.html#importing-datasets-to-r-environment",
    "title": "In-Class Exercise 03",
    "section": "3.0 Importing Datasets to R Environment",
    "text": "3.0 Importing Datasets to R Environment\nIn this exercise, we will use the following datasets:\n\nCHILDCARE, a point feature data providing both location and attribute information of childcare centres. It was downloaded from Data.gov.sg and is in geojson format.\nMP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from Data.gov.sg.\nCostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format.\n\n\n3.1 Importing Geospatial Data\nIn this section, st_read() of sf package will be used to import the three geospatial data sets mentioned in previous section into R environment.\n\nchildcare_sf &lt;- st_read(\"../data/aspatial/child-care-services-geojson.geojson\")\n\nReading layer `child-care-services-geojson' from data source \n  `/Users/khantminnaing/IS415-GAA/data/aspatial/child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\nmpsz_sf &lt;- st_read(dsn = \"../data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/khantminnaing/IS415-GAA/data/geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03.html#geospatial-data-wrangling",
    "href": "In-class_Ex/In-class_Ex03.html#geospatial-data-wrangling",
    "title": "In-Class Exercise 03",
    "section": "4.0 Geospatial Data Wrangling",
    "text": "4.0 Geospatial Data Wrangling\n\n4.1. Assigning Stanadrd Coordinate Systems\n\nchildcare_sf &lt;- st_transform(childcare_sf, crs = 3414)\nmpsz_sf &lt;- st_transform(mpsz_sf, crs = 3414)\n\n\n\n4.2 Creating Coastal Outline\n\nsg_sf &lt;- mpsz_sf %&gt;% st_union()\nplot(sg_sf)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02.html",
    "title": "In-Class Exercise 02",
    "section": "",
    "text": "In this exercise, we will explore how to process and wrangle Grab Posisi dataset."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02.html#overview",
    "href": "In-class_Ex/In-class_Ex02.html#overview",
    "title": "In-Class Exercise 02",
    "section": "",
    "text": "In this exercise, we will explore how to process and wrangle Grab Posisi dataset."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02.html#importing-packages",
    "href": "In-class_Ex/In-class_Ex02.html#importing-packages",
    "title": "In-Class Exercise 02",
    "section": "2.0 Importing Packages",
    "text": "2.0 Importing Packages\nBefore we start the exercise, we will need to import necessary R packages first. We will use the following packages:\n\narrow for reading and writing Apache Parquet files\nlubridate for tackling with temporal data (dates and times)\ntidyverse for manipulating and wrangling data, as well as, implementing data science functions\ntmap for creating and visualizing thematic maps\nsf for handling geospatial data.\n\n\npacman::p_load(arrow,lubridate,tidyverse,tmap,sf)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02.html#importing-datasets-into-r-environment",
    "href": "In-class_Ex/In-class_Ex02.html#importing-datasets-into-r-environment",
    "title": "In-Class Exercise 02",
    "section": "3.0 Importing Datasets into R Environment",
    "text": "3.0 Importing Datasets into R Environment\n\n3.1 Datasets\nIn this exercise, we will use Grab-Posisi dataset, which is a comprehensive GPS trajectory dataset for car-hailing services in Southeast Asia.\n\nApart from the time and location of the object, GPS trajectories are also characterised by other parameters such as speed, the headed direction, the area and distance covered during its travel, and the travelled time. Thus, the trajectory patterns from users GPS data are a valuable source of information for a wide range of urban applications, such as solving transportation problems, traffic prediction, and developing reasonable urban planning.\n\n\n3.1 Importing Grab-Posisi Dataset\nEach trajectory in Grab-Posisi dataset is serialised in a file in Apache Parquet format.\n\nFirstly, we will use read_parquet function from arrow package\n\n\ndf &lt;- read_parquet('~/IS415-GAA/data/GrabPosisi/part-00000.snappy.parquet')\ndf_1 &lt;- read_parquet('~/IS415-GAA/data/GrabPosisi/part-00001.snappy.parquet')\n\n\nNext, we will use head() function to quickly scan through the data columns and values.\n\n\nhead(df)\n\n# A tibble: 6 × 9\n  trj_id driving_mode osname  pingtimestamp rawlat rawlng speed bearing accuracy\n  &lt;chr&gt;  &lt;chr&gt;        &lt;chr&gt;           &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;int&gt;    &lt;dbl&gt;\n1 70014  car          android    1554943236   1.34   104.  18.9     248      3.9\n2 73573  car          android    1555582623   1.32   104.  17.7      44      4  \n3 75567  car          android    1555141026   1.33   104.  14.0      34      3.9\n4 1410   car          android    1555731693   1.26   104.  13.0     181      4  \n5 4354   car          android    1555584497   1.28   104.  14.8      93      3.9\n6 32630  car          android    1555395258   1.30   104.  23.2      73      3.9\n\n\nFrom the result above, we can see that the dataset includes a total of 9 columns as follows:\n\n\n\nColumn Name\nData Type\nRemark\n\n\n\n\ntrj_id\nchr\nTrajectory ID\n\n\ndriving_mode\nchr\nMode of Driving\n\n\nosname\nchr\n\n\n\npingtimestamp\nint\nData Recording Timestamp\n\n\nrawlat\nnum\nLatitude Value (WGS-84)\n\n\nrawlng\nnum\nLongitude Value (WGS-84)\n\n\nspeed\nnum\nSpeed\n\n\nbearing\nint\nBearing\n\n\naccuracy\nnum\nAccuracy\n\n\n\nFrom the above table, it is seen that the pingtimestamp is recorded as int. We need to convert this data to proper datetime format to derive meaningful temporal insights of the data. To do so, we will use as_datetime() function from lubridate package.\n\ndf$pingtimestamp &lt;- as_datetime(df$pingtimestamp)\n\n\n\n3.2 Extracting Trip Starting Locations and Temporal Data Values\nAfter loading the Grab-Posisi dataset, we will extract features that we want to use for analysis. Firstly, we will extract trip starting locations for all trajectories in the dataset and save it into a new df called origin_df.\nAlso, we are interested to derive useful temporal data such as day of the week, hour, and yy-mm-dd. To do so, we will use the following functions from lubridate package, and add the newly derived values as new columns to origin_df.\n\nwday: allows us to get days component of a date-time\nhour: allows us to get hours component of a date-time\nmday: allows us to parse dates with year, month, and day components\n\n\norigin_df &lt;- df %&gt;%\n  group_by(trj_id) %&gt;%\n  arrange(pingtimestamp) %&gt;%\n  filter(row_number()==1) %&gt;% \n  mutate(weekday = wday(pingtimestamp,\n                       label=TRUE,\n                       abbr=TRUE),\n         starting_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n\n\n\n3.3 Extracting Trip Ending Locations and Temporal Data Values\nSimilar to what we did in previous session, we are also interested to extract trip ending locations and associated temporal data into a new df called destination_df. We will use the same functions from previous session here.\n\ndestination_df &lt;- df %&gt;%\n  group_by(trj_id) %&gt;%\n  arrange(desc(pingtimestamp)) %&gt;%\n  filter(row_number()==1) %&gt;% \n  mutate(weekday = wday(pingtimestamp,\n                       label=TRUE,\n                       abbr=TRUE),\n         starting_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n\n\n\n\n\n\n\nReflection\n\n\n\narrange() function sort the timestamps in ascending order by default. Hence, for destination_df, we use arrange(desc()) argument to sort the timestamps in descending order\n\n\n\n\n3.4 Saving R Objects in RDS Format\nRDS (R Data Serialization) files are a common format for saving R objects in RStudio, and they allow us to preserve the state of an object between R sessions. Saving R object as an RDS file in R can be useful for sharing our work with others, replicating our analysis, or simply storing our work for later use.\n\nwrite_rds(origin_df, \"../data/rds/origin_df.rds\")\nwrite_rds(destination_df, \"../data/rds/destination_df.rds\")\n\n\n\n3.4 Importing RDS Objects\n\norigin_df &lt;- read_rds(\"../data/rds/origin_df.rds\")\ndestination_df &lt;- read_rds(\"../data/rds/destination_df.rds\")"
  }
]